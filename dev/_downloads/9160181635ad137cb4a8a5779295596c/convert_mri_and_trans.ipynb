{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 07. Save and load T1-weighted MRI scan along with anatomical landmarks in BIDS\n\nWhen working with MEEG data in the domain of source localization, we usually\nhave to deal with aligning several coordinate systems, such as the coordinate\nsystems of ...\n\n- the head of a study participant\n- the recording device (in the case of MEG)\n- the anatomical MRI scan of a study participant\n\nThe process of aligning these frames is also called coregistration, and is\nperformed with the help of a transformation matrix, called ``trans`` in MNE.\n\nIn this tutorial, we show how ``MNE-BIDS`` can be used to save a T1 weighted\nMRI scan in BIDS format, and to encode all information of the ``trans`` object\nin a BIDS compatible way.\n\nFinally, we will automatically reproduce our ``trans`` object from a BIDS\ndirectory.\n\nSee the documentation pages in the MNE docs for more information on\n[source alignment and coordinate frames](mne_source_coords_)\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>For this example you will need to install ``matplotlib`` and\n          ``nilearn`` on top of your usual ``mne-bids`` installation.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Stefan Appelhoff <stefan.appelhoff@mailbox.org>\n#          Alex Rockhill <aprockhill@mailbox.org>\n#          Alex Gramfort <alexandre.gramfort@inria.fr>\n#\n# License: BSD-3-Clause"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's import everything we need for this example:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport shutil\n\nimport matplotlib.pyplot as plt\nimport mne\nimport numpy as np\nfrom mne import head_to_mri\nfrom mne.datasets import sample\nfrom nilearn.plotting import plot_anat\n\nfrom mne_bids import (\n    BIDSPath,\n    get_anat_landmarks,\n    get_head_mri_trans,\n    print_dir_tree,\n    write_anat,\n    write_raw_bids,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will be using the [MNE sample data](mne_sample_data_) and write a basic\nBIDS dataset. For more information, you can checkout the respective\n`example <ex-convert-mne-sample>`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = sample.data_path()\nevent_id = {\n    \"Auditory/Left\": 1,\n    \"Auditory/Right\": 2,\n    \"Visual/Left\": 3,\n    \"Visual/Right\": 4,\n    \"Smiley\": 5,\n    \"Button\": 32,\n}\nraw_fname = op.join(data_path, \"MEG\", \"sample\", \"sample_audvis_raw.fif\")\nevents_fname = op.join(data_path, \"MEG\", \"sample\", \"sample_audvis_raw-eve.fif\")\noutput_path = op.abspath(op.join(data_path, \"..\", \"MNE-sample-data-bids\"))\nfs_subjects_dir = op.join(data_path, \"subjects\")  # FreeSurfer subjects dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To ensure the output path doesn't contain any leftover files from previous\ntests and example runs, we simply delete it.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Do not delete directories that may contain important data!</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if op.exists(output_path):\n    shutil.rmtree(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the input data and store it as BIDS data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw = mne.io.read_raw_fif(raw_fname)\nraw.info[\"line_freq\"] = 60  # specify power line frequency as required by BIDS\n\nsub = \"01\"\nses = \"01\"\ntask = \"audiovisual\"\nrun = \"01\"\nbids_path = BIDSPath(subject=sub, session=ses, task=task, run=run, root=output_path)\nwrite_raw_bids(raw, bids_path, events=events_fname, event_id=event_id, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the directory tree\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print_dir_tree(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Writing T1 image\n\nNow let's assume that we have also collected some T1 weighted MRI data for\nour subject. And furthermore, that we have already aligned our coordinate\nframes (using e.g., the `coregistration GUI`_) and obtained a transformation\nmatrix :code:`trans`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get the path to our MRI scan\nt1_fname = op.join(fs_subjects_dir, \"sample\", \"mri\", \"T1.mgz\")\n\n# Load the transformation matrix and show what it looks like\ntrans_fname = op.join(data_path, \"MEG\", \"sample\", \"sample_audvis_raw-trans.fif\")\ntrans = mne.read_trans(trans_fname)\nprint(trans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save the MRI to our existing BIDS directory and at the same time\ncreate a JSON sidecar file that contains metadata, we will later use to\nretrieve our transformation matrix :code:`trans`. The metadata will here\nconsist of the coordinates of three anatomical landmarks (LPA, Nasion and\nRPA (=left and right preauricular points) expressed in voxel coordinates\nw.r.t. the T1 image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First create the BIDSPath object.\nt1w_bids_path = BIDSPath(subject=sub, session=ses, root=output_path, suffix=\"T1w\")\n\n# use ``trans`` to transform landmarks from the ``raw`` file to\n# the voxel space of the image\nlandmarks = get_anat_landmarks(\n    t1_fname,  # path to the MRI scan\n    info=raw.info,  # the MEG data file info from the same subject as the MRI\n    trans=trans,  # our transformation matrix\n    fs_subject=\"sample\",  # FreeSurfer subject\n    fs_subjects_dir=fs_subjects_dir,  # FreeSurfer subjects directory\n)\n\n# We use the write_anat function\nt1w_bids_path = write_anat(\n    image=t1_fname,  # path to the MRI scan\n    bids_path=t1w_bids_path,\n    landmarks=landmarks,  # the landmarks in MRI voxel space\n    verbose=True,  # this will print out the sidecar file\n)\nanat_dir = t1w_bids_path.directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's have another look at our BIDS directory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print_dir_tree(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our BIDS dataset is now ready to be shared. We can easily estimate the\ntransformation matrix using ``MNE-BIDS`` and the BIDS dataset.\nThis function converts the anatomical landmarks stored in the T1 sidecar\nfile into FreeSurfer surface RAS space, and aligns the landmarks in the\nelectrophysiology data with them. This way your electrophysiology channel\nlocations can be transformed to surface RAS space using the ``trans`` which\nis crucial for source localization and other uses of the FreeSurfer surfaces.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If this dataset were shared with you, you would first have to use\n          the T1 image as input for the FreeSurfer recon-all, see\n          `tut-freesurfer-mne`.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estim_trans = get_head_mri_trans(\n    bids_path=bids_path, fs_subject=\"sample\", fs_subjects_dir=fs_subjects_dir\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's use the T1 weighted MRI image and plot the anatomical\nlandmarks Nasion, LPA, and RPA onto the brain image. For that, we can\nextract the location of Nasion, LPA, and RPA from the MEG file, apply our\ntransformation matrix :code:`trans`, and plot the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get Landmarks from MEG file, 0, 1, and 2 correspond to LPA, NAS, RPA\n# and the 'r' key will provide us with the xyz coordinates. The coordinates\n# are expressed here in MEG Head coordinate system.\npos = np.asarray(\n    (raw.info[\"dig\"][0][\"r\"], raw.info[\"dig\"][1][\"r\"], raw.info[\"dig\"][2][\"r\"])\n)\n\n# We now use the ``head_to_mri`` function from MNE-Python to convert MEG\n# coordinates to MRI scanner RAS space. For the conversion we use our\n# estimated transformation matrix and the MEG coordinates extracted from the\n# raw file. `subjects` and `subjects_dir` are used internally, to point to\n# the T1-weighted MRI file: `t1_mgh_fname`. Coordinates are is mm.\nmri_pos = head_to_mri(\n    pos=pos, subject=\"sample\", mri_head_t=estim_trans, subjects_dir=fs_subjects_dir\n)\n\n# Our MRI written to BIDS, we got `anat_dir` from our `write_anat` function\nt1_nii_fname = op.join(anat_dir, \"sub-01_ses-01_T1w.nii.gz\")\n\n# Plot it\nfig, axs = plt.subplots(3, 1, figsize=(7, 7), facecolor=\"k\")\nfor point_idx, label in enumerate((\"LPA\", \"NAS\", \"RPA\")):\n    plot_anat(\n        t1_nii_fname,\n        axes=axs[point_idx],\n        cut_coords=mri_pos[point_idx, :],\n        title=label,\n        vmax=160,\n    )\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Writing FLASH MRI image\n\nWe can write another types of MRI data such as FLASH images for BEM models\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "flash_fname = op.join(fs_subjects_dir, \"sample\", \"mri\", \"flash\", \"mef05.mgz\")\n\nflash_bids_path = BIDSPath(subject=sub, session=ses, root=output_path, suffix=\"FLASH\")\n\nwrite_anat(image=flash_fname, bids_path=flash_bids_path, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Writing defaced and anonymized T1 image\n\nWe can deface the MRI for anonymization by passing ``deface=True``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t1w_bids_path = write_anat(\n    image=t1_fname,  # path to the MRI scan\n    bids_path=bids_path,\n    landmarks=landmarks,\n    deface=True,\n    overwrite=True,\n    verbose=True,  # this will print out the sidecar file\n)\nanat_dir = t1w_bids_path.directory\n\n# Our MRI written to BIDS, we got `anat_dir` from our `write_anat` function\nt1_nii_fname = op.join(anat_dir, \"sub-01_ses-01_T1w.nii.gz\")\n\n# Plot it\nfig, ax = plt.subplots()\nplot_anat(t1_nii_fname, axes=ax, title=\"Defaced\", vmax=160)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Writing defaced and anonymized FLASH MRI image\n\nDefacing the FLASH works just like the T1 as long as they are aligned.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# use ``trans`` to transform landmarks from the ``raw`` file to\n# the voxel space of the image\nlandmarks = get_anat_landmarks(\n    flash_fname,  # path to the FLASH scan\n    info=raw.info,  # the MEG data file info from the same subject as the MRI\n    trans=trans,  # our transformation matrix\n    fs_subject=\"sample\",  # freesurfer subject\n    fs_subjects_dir=fs_subjects_dir,  # freesurfer subjects directory\n)\n\nflash_bids_path = write_anat(\n    image=flash_fname,  # path to the MRI scan\n    bids_path=flash_bids_path,\n    landmarks=landmarks,\n    deface=True,\n    overwrite=True,\n    verbose=True,  # this will print out the sidecar file\n)\n\n# Our MRI written to BIDS, we got `anat_dir` from our `write_anat` function\nflash_nii_fname = op.join(anat_dir, \"sub-01_ses-01_FLASH.nii.gz\")\n\n# Plot it\nfig, ax = plt.subplots()\nplot_anat(flash_nii_fname, axes=ax, title=\"Defaced\", vmax=700)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using manual landmark coordinates in scanner RAS\n\nYou can also find landmarks with a 3D image viewer (e.g. FreeView) if you\nhave not aligned the channel locations (including fiducials) using the\ncoregistration GUI or if this is just more convenient.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In FreeView, you need to use \"RAS\" and not \"TkReg RAS\" for this.\n          You can also use voxel coordinates but, in FreeView, they\n          are integers and so not as precise as the \"RAS\" decimal numbers.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "flash_ras_landmarks = (\n    np.array(\n        [\n            [-74.53102838, 19.62854953, -52.2888194],\n            [-1.89454315, 103.69850925, 4.97120376],\n            [72.01200673, 21.09274883, -57.53678375],\n        ]\n    )\n    / 1e3\n)  # mm -> m\n\nlandmarks = mne.channels.make_dig_montage(\n    lpa=flash_ras_landmarks[0],\n    nasion=flash_ras_landmarks[1],\n    rpa=flash_ras_landmarks[2],\n    coord_frame=\"ras\",\n)\n\nflash_bids_path = write_anat(\n    image=flash_fname,  # path to the MRI scan\n    bids_path=flash_bids_path,\n    landmarks=landmarks,\n    deface=True,\n    overwrite=True,\n    verbose=True,  # this will print out the sidecar file\n)\n\n# Plot it\nfig, ax = plt.subplots()\nplot_anat(flash_nii_fname, axes=ax, title=\"Defaced\", vmax=700)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. LINKS\n\n   https://mne.tools/stable/auto_tutorials/forward/20_source_alignment.html#defining-the-headmri-trans-using-the-gui\n   https://mne.tools/stable/auto_tutorials/source-modeling/plot_source_alignment.html\n   https://mne.tools/stable/documentation/datasets.html#sample\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}