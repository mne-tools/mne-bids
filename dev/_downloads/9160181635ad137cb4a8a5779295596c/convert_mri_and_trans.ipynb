{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n==============================================================================\n07. Save and load T1-weighted MRI scan along with anatomical landmarks in BIDS\n==============================================================================\n\nWhen working with MEEG data in the domain of source localization, we usually\nhave to deal with aligning several coordinate systems, such as the coordinate\nsystems of ...\n\n- the head of a study participant\n- the recording device (in the case of MEG)\n- the anatomical MRI scan of a study participant\n\nThe process of aligning these frames is also called coregistration, and is\nperformed with the help of a transformation matrix, called ``trans`` in MNE.\n\nIn this tutorial, we show how ``MNE-BIDS`` can be used to save a T1 weighted\nMRI scan in BIDS format, and to encode all information of the ``trans`` object\nin a BIDS compatible way.\n\nFinally, we will automatically reproduce our ``trans`` object from a BIDS\ndirectory.\n\nSee the documentation pages in the MNE docs for more information on\n`source alignment and coordinate frames <mne_source_coords_>`_\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>For this example you will need to install ``matplotlib`` and\n          ``nilearn`` on top of your usual ``mne-bids`` installation.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Stefan Appelhoff <stefan.appelhoff@mailbox.org>\n# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are importing everything we need for this example:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport shutil as sh\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom nilearn.plotting import plot_anat\n\nimport mne\nfrom mne.datasets import sample\nfrom mne.source_space import head_to_mri\n\nfrom mne_bids import (write_raw_bids, BIDSPath, write_anat,\n                      get_head_mri_trans, print_dir_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will be using the `MNE sample data <mne_sample_data_>`_ and write a basic\nBIDS dataset. For more information, you can checkout the respective\n`example <ex-convert-mne-sample>`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = sample.data_path()\nevent_id = {'Auditory/Left': 1, 'Auditory/Right': 2, 'Visual/Left': 3,\n            'Visual/Right': 4, 'Smiley': 5, 'Button': 32}\nraw_fname = op.join(data_path, 'MEG', 'sample', 'sample_audvis_raw.fif')\nevents_data = op.join(data_path, 'MEG', 'sample', 'sample_audvis_raw-eve.fif')\noutput_path = op.abspath(op.join(data_path, '..', 'MNE-sample-data-bids'))\nif op.exists(output_path):\n    sh.rmtree(output_path)\nraw = mne.io.read_raw_fif(raw_fname)\nraw.info['line_freq'] = 60  # specify power line frequency as required by BIDS\n\nsub = '01'\nses = '01'\ntask = 'audiovisual'\nrun = '01'\nbids_basename = BIDSPath(subject=sub, session=ses, task=task,\n                         run=run)\nwrite_raw_bids(raw, bids_basename, output_path, events_data=events_data,\n               event_id=event_id, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the directory tree\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print_dir_tree(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's assume that we have also collected some T1 weighted MRI data for\nour subject. And furthermore, that we have already aligned our coordinate\nframes (using e.g., the `coregistration GUI`_) and obtained a transformation\nmatrix :code:`trans`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get the path to our MRI scan\nt1_mgh_fname = op.join(data_path, 'subjects', 'sample', 'mri', 'T1.mgz')\n\n# Load the transformation matrix and show what it looks like\ntrans_fname = op.join(data_path, 'MEG', 'sample',\n                      'sample_audvis_raw-trans.fif')\ntrans = mne.read_trans(trans_fname)\nprint(trans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save the MRI to our existing BIDS directory and at the same time\ncreate a JSON sidecar file that contains metadata, we will later use to\nretrieve our transformation matrix :code:`trans`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We use the write_anat function\nanat_dir = write_anat(bids_root=output_path,  # the BIDS dir we wrote earlier\n                      subject=sub,\n                      t1w=t1_mgh_fname,  # path to the MRI scan\n                      session=ses,\n                      raw=raw,  # the raw MEG data file connected to the MRI\n                      trans=trans,  # our transformation matrix\n                      verbose=True  # this will print out the sidecar file\n                      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's have another look at our BIDS directory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print_dir_tree(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our BIDS dataset is now ready to be shared. We can easily estimate the\ntransformation matrix using ``MNE-BIDS`` and the BIDS dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estim_trans = get_head_mri_trans(bids_basename=bids_basename,\n                                 bids_root=output_path  # root of our BIDS dir\n                                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's use the T1 weighted MRI image and plot the anatomical\nlandmarks Nasion, LPA, and RPA (=left and right preauricular points) onto\nthe brain image. For that, we can extract the location of Nasion, LPA, and\nRPA from the MEG file, apply our transformation matrix :code:`trans`, and\nplot the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get Landmarks from MEG file, 0, 1, and 2 correspond to LPA, NAS, RPA\n# and the 'r' key will provide us with the xyz coordinates\npos = np.asarray((raw.info['dig'][0]['r'],\n                  raw.info['dig'][1]['r'],\n                  raw.info['dig'][2]['r']))\n\n\n# We use a function from MNE-Python to convert MEG coordinates to MRI space\n# for the conversion we use our estimated transformation matrix and the\n# MEG coordinates extracted from the raw file. `subjects` and `subjects_dir`\n# are used internally, to point to the T1-weighted MRI file: `t1_mgh_fname`\nmri_pos = head_to_mri(pos=pos,\n                      subject='sample',\n                      mri_head_t=estim_trans,\n                      subjects_dir=op.join(data_path, 'subjects')\n                      )\n\n# Our MRI written to BIDS, we got `anat_dir` from our `write_anat` function\nt1_nii_fname = op.join(anat_dir, 'sub-01_ses-01_T1w.nii.gz')\n\n# Plot it\nfig, axs = plt.subplots(3, 1)\nfor point_idx, label in enumerate(('LPA', 'NAS', 'RPA')):\n    plot_anat(t1_nii_fname, axes=axs[point_idx],\n              cut_coords=mri_pos[point_idx, :],\n              title=label)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can deface the MRI for anonymization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "anat_dir = write_anat(bids_root=output_path,  # the BIDS dir we wrote earlier\n                      subject=sub,\n                      t1w=t1_mgh_fname,  # path to the MRI scan\n                      session=ses,\n                      raw=raw,  # the raw MEG data file connected to the MRI\n                      trans=trans,  # our transformation matrix\n                      deface=True,\n                      overwrite=True,\n                      verbose=True  # this will print out the sidecar file\n                      )\n\n# Our MRI written to BIDS, we got `anat_dir` from our `write_anat` function\nt1_nii_fname = op.join(anat_dir, 'sub-01_ses-01_T1w.nii.gz')\n\n# Plot it\nfig, ax = plt.subplots()\nplot_anat(t1_nii_fname, axes=ax, title='Defaced')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. LINKS\n\n   https://martinos.org/mne/stable/auto_tutorials/source-modeling/plot_source_alignment.html#defining-the-headmri-trans-using-the-gui  # noqa: E501\n   https://www.martinos.org/mne/stable/auto_tutorials/source-modeling/plot_source_alignment.html  # noqa: E501\n   https://martinos.org/mne/stable/manual/sample_dataset.html\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}