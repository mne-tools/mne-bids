.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_convert_mri_and_trans.py>`     to download the full example code or to run this example in your browser via Binder
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_examples_convert_mri_and_trans.py:


==============================================================================
07. Save and load T1-weighted MRI scan along with anatomical landmarks in BIDS
==============================================================================

When working with MEEG data in the domain of source localization, we usually
have to deal with aligning several coordinate systems, such as the coordinate
systems of ...

- the head of a study participant
- the recording device (in the case of MEG)
- the anatomical MRI scan of a study participant

The process of aligning these frames is also called coregistration, and is
performed with the help of a transformation matrix, called ``trans`` in MNE.

In this tutorial, we show how ``MNE-BIDS`` can be used to save a T1 weighted
MRI scan in BIDS format, and to encode all information of the ``trans`` object
in a BIDS compatible way.

Finally, we will automatically reproduce our ``trans`` object from a BIDS
directory.

See the documentation pages in the MNE docs for more information on
`source alignment and coordinate frames <mne_source_coords_>`_

.. note:: For this example you will need to install ``matplotlib`` and
          ``nilearn`` on top of your usual ``mne-bids`` installation.


.. code-block:: default

    # Authors: Stefan Appelhoff <stefan.appelhoff@mailbox.org>
    # License: BSD (3-clause)








We are importing everything we need for this example:


.. code-block:: default


    import os.path as op
    import shutil as sh

    import numpy as np
    import matplotlib.pyplot as plt

    from nilearn.plotting import plot_anat

    import mne
    from mne.datasets import sample
    from mne.source_space import head_to_mri

    from mne_bids import (write_raw_bids, BIDSPath, write_anat,
                          get_head_mri_trans, print_dir_tree)








We will be using the `MNE sample data <mne_sample_data_>`_ and write a basic
BIDS dataset. For more information, you can checkout the respective
:ref:`example <ex-convert-mne-sample>`.


.. code-block:: default


    data_path = sample.data_path()
    event_id = {'Auditory/Left': 1, 'Auditory/Right': 2, 'Visual/Left': 3,
                'Visual/Right': 4, 'Smiley': 5, 'Button': 32}
    raw_fname = op.join(data_path, 'MEG', 'sample', 'sample_audvis_raw.fif')
    events_data = op.join(data_path, 'MEG', 'sample', 'sample_audvis_raw-eve.fif')
    output_path = op.abspath(op.join(data_path, '..', 'MNE-sample-data-bids'))
    if op.exists(output_path):
        sh.rmtree(output_path)
    raw = mne.io.read_raw_fif(raw_fname)
    raw.info['line_freq'] = 60  # specify power line frequency as required by BIDS

    sub = '01'
    ses = '01'
    task = 'audiovisual'
    run = '01'
    bids_path = BIDSPath(subject=sub, session=ses, task=task,
                         run=run, root=output_path)
    write_raw_bids(raw, bids_path, events_data=events_data,
                   event_id=event_id, overwrite=True)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...
        Read a total of 3 projection items:
            PCA-v1 (1 x 102)  idle
            PCA-v2 (1 x 102)  idle
            PCA-v3 (1 x 102)  idle
        Range : 25800 ... 192599 =     42.956 ...   320.670 secs
    Ready.
    Opening raw data file /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...
        Read a total of 3 projection items:
            PCA-v1 (1 x 102)  idle
            PCA-v2 (1 x 102)  idle
            PCA-v3 (1 x 102)  idle
        Range : 25800 ... 192599 =     42.956 ...   320.670 secs
    Ready.
    Creating folder: /home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg

    Writing '/home/circleci/mne_data/MNE-sample-data-bids/README'...

    References
    ----------
    Appelhoff, S., Sanderson, M., Brooks, T., Vliet, M., Quentin, R., Holdgraf, C., Chaumon, M., Mikulan, E., Tavabi, K., HÃ¶chenberger, R., Welke, D., Brunner, C., Rockhill, A., Larson, E., Gramfort, A. and Jas, M. (2019). MNE-BIDS: Organizing electrophysiological data into the BIDS format and facilitating their analysis. Journal of Open Source Software 4: (1896). https://doi.org/10.21105/joss.01896

    Niso, G., Gorgolewski, K. J., Bock, E., Brooks, T. L., Flandin, G., Gramfort, A., Henson, R. N., Jas, M., Litvak, V., Moreau, J., Oostenveld, R., Schoffelen, J., Tadel, F., Wexler, J., Baillet, S. (2018). MEG-BIDS, the brain imaging data structure extended to magnetoencephalography. Scientific Data, 5, 180110. http://doi.org/10.1038/sdata.2018.110


    Writing '/home/circleci/mne_data/MNE-sample-data-bids/participants.tsv'...

    participant_id  age     sex     hand
    sub-01  n/a     n/a     n/a

    Writing '/home/circleci/mne_data/MNE-sample-data-bids/participants.json'...

    {
        "participant_id": {
            "Description": "Unique participant identifier"
        },
        "age": {
            "Description": "Age of the participant at time of testing",
            "Units": "years"
        },
        "sex": {
            "Description": "Biological sex of the participant",
            "Levels": {
                "F": "female",
                "M": "male"
            }
        },
        "hand": {
            "Description": "Handedness of the participant",
            "Levels": {
                "R": "right",
                "L": "left",
                "A": "ambidextrous"
            }
        }
    }

    Writing '/home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_coordsystem.json'...

    {
        "MEGCoordinateSystem": "Elekta",
        "MEGCoordinateUnits": "m",
        "MEGCoordinateSystemDescription": "n/a",
        "HeadCoilCoordinates": {
            "NAS": [
                3.725290298461914e-09,
                0.10260561108589172,
                4.190951585769653e-09
            ],
            "LPA": [
                -0.07137660682201385,
                0.0,
                5.122274160385132e-09
            ],
            "RPA": [
                0.07526767998933792,
                0.0,
                5.587935447692871e-09
            ],
            "coil1": [
                0.032922741025686264,
                0.09897983074188232,
                0.07984329760074615
            ],
            "coil2": [
                -0.06998106092214584,
                0.06771647930145264,
                0.06888450682163239
            ],
            "coil3": [
                -0.07260829955339432,
                -0.02086828649044037,
                0.0971473976969719
            ],
            "coil4": [
                0.04996863007545471,
                -0.007233052980154753,
                0.1228904277086258
            ]
        },
        "HeadCoilCoordinateSystem": "RAS",
        "HeadCoilCoordinateUnits": "m"
    }

    Writing '/home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_task-audiovisual_run-01_events.tsv'...

    onset   duration        trial_type      value   sample
    3.6246181587150867      0.0     Auditory/Right  2       2177
    4.237323479067476       0.0     Visual/Left     3       2545
    4.946596485779753       0.0     Auditory/Left   1       2971
    5.692498614904401       0.0     Visual/Right    4       3419
    6.41342634238425        0.0     Auditory/Right  2       3852

    Writing '/home/circleci/mne_data/MNE-sample-data-bids/dataset_description.json'...

    {
        "Name": " ",
        "BIDSVersion": "1.4.0",
        "DatasetType": "raw",
        "Authors": [
            "Please cite MNE-BIDS in your publication before removing this (citations in README)"
        ]
    }
    Reading 0 ... 166799  =      0.000 ...   277.714 secs...

    Writing '/home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_task-audiovisual_run-01_meg.json'...

    {
        "TaskName": "audiovisual",
        "Manufacturer": "Elekta",
        "PowerLineFrequency": 60,
        "SamplingFrequency": 600.614990234375,
        "SoftwareFilters": "n/a",
        "RecordingDuration": 277.7136813300495,
        "RecordingType": "continuous",
        "DewarPosition": "n/a",
        "DigitizedLandmarks": false,
        "DigitizedHeadPoints": false,
        "MEGChannelCount": 306,
        "MEGREFChannelCount": 0,
        "EEGChannelCount": 60,
        "EOGChannelCount": 1,
        "ECGChannelCount": 0,
        "EMGChannelCount": 0,
        "MiscChannelCount": 0,
        "TriggerChannelCount": 9
    }

    Writing '/home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_task-audiovisual_run-01_channels.tsv'...

    name    type    units   low_cutoff      high_cutoff     description     sampling_frequency      status  status_description
    MEG 0113        MEGGRADPLANAR   T/m     0.10000000149011612     172.17630004882812      Planar Gradiometer      600.614990234375        good    n/a
    MEG 0112        MEGGRADPLANAR   T/m     0.10000000149011612     172.17630004882812      Planar Gradiometer      600.614990234375        good    n/a
    MEG 0111        MEGMAG  T       0.10000000149011612     172.17630004882812      Magnetometer    600.614990234375        good    n/a
    MEG 0122        MEGGRADPLANAR   T/m     0.10000000149011612     172.17630004882812      Planar Gradiometer      600.614990234375        good    n/a
    MEG 0123        MEGGRADPLANAR   T/m     0.10000000149011612     172.17630004882812      Planar Gradiometer      600.614990234375        good    n/a
    Copying data files to /home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_task-audiovisual_run-01_meg
    Writing /home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_task-audiovisual_run-01_meg.fif
    Closing /home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_task-audiovisual_run-01_meg.fif [done]

    Writing '/home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/sub-01_ses-01_scans.tsv'...

    filename        acq_time
    meg/sub-01_ses-01_task-audiovisual_run-01_meg.fif       2002-12-03T19:01:10
    Wrote /home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/sub-01_ses-01_scans.tsv entry with meg/sub-01_ses-01_task-audiovisual_run-01_meg.fif.

    '/home/circleci/mne_data/MNE-sample-data-bids'



Print the directory tree


.. code-block:: default

    print_dir_tree(output_path)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    |MNE-sample-data-bids/
    |--- README
    |--- dataset_description.json
    |--- participants.tsv
    |--- participants.json
    |--- sub-01/
    |------ ses-01/
    |--------- sub-01_ses-01_scans.tsv
    |--------- meg/
    |------------ sub-01_ses-01_task-audiovisual_run-01_channels.tsv
    |------------ sub-01_ses-01_task-audiovisual_run-01_meg.fif
    |------------ sub-01_ses-01_task-audiovisual_run-01_meg.json
    |------------ sub-01_ses-01_coordsystem.json
    |------------ sub-01_ses-01_task-audiovisual_run-01_events.tsv




Now let's assume that we have also collected some T1 weighted MRI data for
our subject. And furthermore, that we have already aligned our coordinate
frames (using e.g., the `coregistration GUI`_) and obtained a transformation
matrix :code:`trans`.


.. code-block:: default


    # Get the path to our MRI scan
    t1_mgh_fname = op.join(data_path, 'subjects', 'sample', 'mri', 'T1.mgz')

    # Load the transformation matrix and show what it looks like
    trans_fname = op.join(data_path, 'MEG', 'sample',
                          'sample_audvis_raw-trans.fif')
    trans = mne.read_trans(trans_fname)
    print(trans)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <Transform | head->MRI (surface RAS)>
    [[ 0.99930954  0.01275934  0.0348942   0.00206991]
     [ 0.00998479  0.81240475 -0.58300853  0.01130214]
     [-0.03578702  0.58295429  0.81171638 -0.02755522]
     [ 0.          0.          0.          1.        ]]




We can save the MRI to our existing BIDS directory and at the same time
create a JSON sidecar file that contains metadata, we will later use to
retrieve our transformation matrix :code:`trans`.


.. code-block:: default


    # We use the write_anat function
    anat_dir = write_anat(bids_root=output_path,  # the BIDS dir we wrote earlier
                          subject=sub,
                          t1w=t1_mgh_fname,  # path to the MRI scan
                          session=ses,
                          raw=raw,  # the raw MEG data file connected to the MRI
                          trans=trans,  # our transformation matrix
                          verbose=True  # this will print out the sidecar file
                          )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    Writing '/home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/anat/sub-01_ses-01_T1w.json'...

    {
        "AnatomicalLandmarkCoordinates": {
            "LPA": [
                197.25741411263368,
                153.0008593581418,
                138.5894600936019
            ],
            "NAS": [
                124.62090614299716,
                95.74083565348268,
                222.65942693440599
            ],
            "RPA": [
                50.71437932937833,
                158.24882153365422,
                140.05367187187042
            ]
        }
    }




Let's have another look at our BIDS directory


.. code-block:: default

    print_dir_tree(output_path)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    |MNE-sample-data-bids/
    |--- README
    |--- dataset_description.json
    |--- participants.tsv
    |--- participants.json
    |--- sub-01/
    |------ ses-01/
    |--------- sub-01_ses-01_scans.tsv
    |--------- anat/
    |------------ sub-01_ses-01_T1w.json
    |------------ sub-01_ses-01_T1w.nii.gz
    |--------- meg/
    |------------ sub-01_ses-01_task-audiovisual_run-01_channels.tsv
    |------------ sub-01_ses-01_task-audiovisual_run-01_meg.fif
    |------------ sub-01_ses-01_task-audiovisual_run-01_meg.json
    |------------ sub-01_ses-01_coordsystem.json
    |------------ sub-01_ses-01_task-audiovisual_run-01_events.tsv




Our BIDS dataset is now ready to be shared. We can easily estimate the
transformation matrix using ``MNE-BIDS`` and the BIDS dataset.


.. code-block:: default

    estim_trans = get_head_mri_trans(bids_path=bids_path)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Opening raw data file /home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_task-audiovisual_run-01_meg.fif...
        Read a total of 3 projection items:
            PCA-v1 (1 x 102)  idle
            PCA-v2 (1 x 102)  idle
            PCA-v3 (1 x 102)  idle
        Range : 25800 ... 192599 =     42.956 ...   320.670 secs
    Ready.
    Reading events from /home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_task-audiovisual_run-01_events.tsv.
    Reading channel info from /home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/meg/sub-01_ses-01_task-audiovisual_run-01_channels.tsv.
    /home/circleci/project/mne_bids/read.py:253: RuntimeWarning: The unit for channel(s) STI 001, STI 002, STI 003, STI 004, STI 005, STI 006, STI 014, STI 015, STI 016 has changed from V to NA.
      raw.set_channel_types(channel_type_dict)
    /home/circleci/project/mne_bids/path.py:760: RuntimeWarning: Did not find any electrodes.tsv associated with sub-01_ses-01_task-audiovisual_run-01.

    The search_str was "/home/circleci/mne_data/MNE-sample-data-bids/sub-01/**/sub-01_ses-01*electrodes.tsv"
      warn(msg)




Finally, let's use the T1 weighted MRI image and plot the anatomical
landmarks Nasion, LPA, and RPA (=left and right preauricular points) onto
the brain image. For that, we can extract the location of Nasion, LPA, and
RPA from the MEG file, apply our transformation matrix :code:`trans`, and
plot the results.


.. code-block:: default


    # Get Landmarks from MEG file, 0, 1, and 2 correspond to LPA, NAS, RPA
    # and the 'r' key will provide us with the xyz coordinates
    pos = np.asarray((raw.info['dig'][0]['r'],
                      raw.info['dig'][1]['r'],
                      raw.info['dig'][2]['r']))


    # We use a function from MNE-Python to convert MEG coordinates to MRI space
    # for the conversion we use our estimated transformation matrix and the
    # MEG coordinates extracted from the raw file. `subjects` and `subjects_dir`
    # are used internally, to point to the T1-weighted MRI file: `t1_mgh_fname`
    mri_pos = head_to_mri(pos=pos,
                          subject='sample',
                          mri_head_t=estim_trans,
                          subjects_dir=op.join(data_path, 'subjects')
                          )

    # Our MRI written to BIDS, we got `anat_dir` from our `write_anat` function
    t1_nii_fname = op.join(anat_dir, 'sub-01_ses-01_T1w.nii.gz')

    # Plot it
    fig, axs = plt.subplots(3, 1)
    for point_idx, label in enumerate(('LPA', 'NAS', 'RPA')):
        plot_anat(t1_nii_fname, axes=axs[point_idx],
                  cut_coords=mri_pos[point_idx, :],
                  title=label)
    plt.show()




.. image:: /auto_examples/images/sphx_glr_convert_mri_and_trans_001.png
    :alt: convert mri and trans
    :class: sphx-glr-single-img





We can deface the MRI for anonymization


.. code-block:: default

    anat_dir = write_anat(bids_root=output_path,  # the BIDS dir we wrote earlier
                          subject=sub,
                          t1w=t1_mgh_fname,  # path to the MRI scan
                          session=ses,
                          raw=raw,  # the raw MEG data file connected to the MRI
                          trans=trans,  # our transformation matrix
                          deface=True,
                          overwrite=True,
                          verbose=True  # this will print out the sidecar file
                          )

    # Our MRI written to BIDS, we got `anat_dir` from our `write_anat` function
    t1_nii_fname = op.join(anat_dir, 'sub-01_ses-01_T1w.nii.gz')

    # Plot it
    fig, ax = plt.subplots()
    plot_anat(t1_nii_fname, axes=ax, title='Defaced')
    plt.show()




.. image:: /auto_examples/images/sphx_glr_convert_mri_and_trans_002.png
    :alt: convert mri and trans
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    Writing '/home/circleci/mne_data/MNE-sample-data-bids/sub-01/ses-01/anat/sub-01_ses-01_T1w.json'...

    {
        "AnatomicalLandmarkCoordinates": {
            "LPA": [
                197.25741411263368,
                153.0008593581418,
                138.5894600936019
            ],
            "NAS": [
                124.62090614299716,
                95.74083565348268,
                222.65942693440599
            ],
            "RPA": [
                50.71437932937833,
                158.24882153365422,
                140.05367187187042
            ]
        }
    }




.. LINKS

.. _coregistration GUI:
   https://martinos.org/mne/stable/auto_tutorials/source-modeling/plot_source_alignment.html#defining-the-headmri-trans-using-the-gui  # noqa: E501
.. _mne_source_coords:
   https://www.martinos.org/mne/stable/auto_tutorials/source-modeling/plot_source_alignment.html  # noqa: E501
.. _mne_sample_data:
   https://martinos.org/mne/stable/manual/sample_dataset.html



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  14.598 seconds)


.. _sphx_glr_download_auto_examples_convert_mri_and_trans.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: https://mybinder.org/badge_logo.svg
      :target: https://mybinder.org/v2/gh/mne-tools/mne-bids/gh-pages?filepath=dev/notebooks/auto_examples/convert_mri_and_trans.ipynb
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: convert_mri_and_trans.py <convert_mri_and_trans.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: convert_mri_and_trans.ipynb <convert_mri_and_trans.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
