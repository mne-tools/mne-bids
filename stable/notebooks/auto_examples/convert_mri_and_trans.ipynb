{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 07. Save and load T1-weighted MRI scan along with anatomical landmarks in BIDS\n\nWhen working with MEEG data in the domain of source localization, we usually\nhave to deal with aligning several coordinate systems, such as the coordinate\nsystems of ...\n\n- the head of a study participant\n- the recording device (in the case of MEG)\n- the anatomical MRI scan of a study participant\n\nThe process of aligning these frames is also called coregistration, and is\nperformed with the help of a transformation matrix, called ``trans`` in MNE.\n\nIn this tutorial, we show how ``MNE-BIDS`` can be used to save a T1 weighted\nMRI scan in BIDS format, and to encode all information of the ``trans`` object\nin a BIDS compatible way.\n\nFinally, we will automatically reproduce our ``trans`` object from a BIDS\ndirectory.\n\nSee the documentation pages in the MNE docs for more information on\n`source alignment and coordinate frames <mne_source_coords_>`_\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>For this example you will need to install ``matplotlib`` and\n          ``nilearn`` on top of your usual ``mne-bids`` installation.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Stefan Appelhoff <stefan.appelhoff@mailbox.org>\n# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are importing everything we need for this example:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path as op\nimport shutil as sh\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom nilearn.plotting import plot_anat\n\nimport mne\nfrom mne.datasets import sample\nfrom mne.source_space import head_to_mri\n\nfrom mne_bids import (write_raw_bids, BIDSPath, write_anat,\n                      get_head_mri_trans, print_dir_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will be using the `MNE sample data <mne_sample_data_>`_ and write a basic\nBIDS dataset. For more information, you can checkout the respective\n`example <ex-convert-mne-sample>`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = sample.data_path()\nevent_id = {'Auditory/Left': 1, 'Auditory/Right': 2, 'Visual/Left': 3,\n            'Visual/Right': 4, 'Smiley': 5, 'Button': 32}\nraw_fname = op.join(data_path, 'MEG', 'sample', 'sample_audvis_raw.fif')\nevents_data = op.join(data_path, 'MEG', 'sample', 'sample_audvis_raw-eve.fif')\noutput_path = op.abspath(op.join(data_path, '..', 'MNE-sample-data-bids'))\nif op.exists(output_path):\n    sh.rmtree(output_path)\nraw = mne.io.read_raw_fif(raw_fname)\nraw.info['line_freq'] = 60  # specify power line frequency as required by BIDS\n\nsub = '01'\nses = '01'\ntask = 'audiovisual'\nrun = '01'\nbids_path = BIDSPath(subject=sub, session=ses, task=task,\n                     run=run, root=output_path)\nwrite_raw_bids(raw, bids_path, events_data=events_data,\n               event_id=event_id, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the directory tree\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print_dir_tree(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's assume that we have also collected some T1 weighted MRI data for\nour subject. And furthermore, that we have already aligned our coordinate\nframes (using e.g., the `coregistration GUI`_) and obtained a transformation\nmatrix :code:`trans`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get the path to our MRI scan\nt1_mgh_fname = op.join(data_path, 'subjects', 'sample', 'mri', 'T1.mgz')\n\n# Load the transformation matrix and show what it looks like\ntrans_fname = op.join(data_path, 'MEG', 'sample',\n                      'sample_audvis_raw-trans.fif')\ntrans = mne.read_trans(trans_fname)\nprint(trans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save the MRI to our existing BIDS directory and at the same time\ncreate a JSON sidecar file that contains metadata, we will later use to\nretrieve our transformation matrix :code:`trans`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# First create the BIDSPath object.\nt1w_bids_path = BIDSPath(subject=sub, session=ses, root=output_path)\n\n# We use the write_anat function\nt1w_bids_path = write_anat(\n    t1w=t1_mgh_fname,  # path to the MRI scan\n    bids_path=t1w_bids_path,\n    raw=raw,  # the raw MEG data file connected to the MRI\n    trans=trans,  # our transformation matrix\n    verbose=True  # this will print out the sidecar file\n)\nanat_dir = t1w_bids_path.directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's have another look at our BIDS directory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print_dir_tree(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our BIDS dataset is now ready to be shared. We can easily estimate the\ntransformation matrix using ``MNE-BIDS`` and the BIDS dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estim_trans = get_head_mri_trans(bids_path=bids_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's use the T1 weighted MRI image and plot the anatomical\nlandmarks Nasion, LPA, and RPA (=left and right preauricular points) onto\nthe brain image. For that, we can extract the location of Nasion, LPA, and\nRPA from the MEG file, apply our transformation matrix :code:`trans`, and\nplot the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get Landmarks from MEG file, 0, 1, and 2 correspond to LPA, NAS, RPA\n# and the 'r' key will provide us with the xyz coordinates\npos = np.asarray((raw.info['dig'][0]['r'],\n                  raw.info['dig'][1]['r'],\n                  raw.info['dig'][2]['r']))\n\n\n# We use a function from MNE-Python to convert MEG coordinates to MRI space\n# for the conversion we use our estimated transformation matrix and the\n# MEG coordinates extracted from the raw file. `subjects` and `subjects_dir`\n# are used internally, to point to the T1-weighted MRI file: `t1_mgh_fname`\nmri_pos = head_to_mri(pos=pos,\n                      subject='sample',\n                      mri_head_t=estim_trans,\n                      subjects_dir=op.join(data_path, 'subjects')\n                      )\n\n# Our MRI written to BIDS, we got `anat_dir` from our `write_anat` function\nt1_nii_fname = op.join(anat_dir, 'sub-01_ses-01_T1w.nii.gz')\n\n# Plot it\nfig, axs = plt.subplots(3, 1)\nfor point_idx, label in enumerate(('LPA', 'NAS', 'RPA')):\n    plot_anat(t1_nii_fname, axes=axs[point_idx],\n              cut_coords=mri_pos[point_idx, :],\n              title=label)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can deface the MRI for anonymization by passing ``deface=True``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t1w_bids_path = write_anat(\n    t1w=t1_mgh_fname,  # path to the MRI scan\n    bids_path=bids_path,\n    raw=raw,  # the raw MEG data file connected to the MRI\n    trans=trans,  # our transformation matrix\n    deface=True,\n    overwrite=True,\n    verbose=True  # this will print out the sidecar file\n)\nanat_dir = t1w_bids_path.directory\n\n# Our MRI written to BIDS, we got `anat_dir` from our `write_anat` function\nt1_nii_fname = op.join(anat_dir, 'sub-01_ses-01_T1w.nii.gz')\n\n# Plot it\nfig, ax = plt.subplots()\nplot_anat(t1_nii_fname, axes=ax, title='Defaced')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. LINKS\n\n   https://martinos.org/mne/stable/auto_tutorials/source-modeling/plot_source_alignment.html#defining-the-headmri-trans-using-the-gui  # noqa: E501\n   https://www.martinos.org/mne/stable/auto_tutorials/source-modeling/plot_source_alignment.html  # noqa: E501\n   https://martinos.org/mne/stable/manual/sample_dataset.html\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}